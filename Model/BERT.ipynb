{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BERT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\wissa\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.35.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.16.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.24.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: nltk in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.19.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.3.2)\n",
      "Requirement already satisfied: click in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from nltk->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from torchvision->sentence-transformers) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\wissa\\anaconda3\\lib\\site-packages (2.1.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: tensorflow in c:\\users\\wissa\\anaconda3\\lib\\site-packages (2.15.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.15.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow) (2.15.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes~=0.2.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.23.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (4.7.1)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (1.59.3)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in c:\\users\\wissa\\appdata\\roaming\\python\\python311\\site-packages (from tensorflow-intel==2.15.0->tensorflow) (2.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.15.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.23.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.1.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow-intel==2.15.0->tensorflow) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most relevant answer: When Mane will share confidential information with another person or entity.  Also, when someone will observe or learn about Mane's confidential information. Additionally, when any of the parties (MANE and Counterparty) wish to disclose confidential information to each other.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Load the JSON file containing questions and answers\n",
    "with open('modified_faq_data.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "# User's question\n",
    "user_question = input(\"Ask a question: \")\n",
    "\n",
    "# Tokenize and encode the user's question\n",
    "user_question_tokens = tokenizer.encode(user_question, truncation=True, max_length=512, return_tensors='pt')\n",
    "user_question_embedding = model(input_ids=user_question_tokens).last_hidden_state.mean(dim=1)\n",
    "\n",
    "# Calculate cosine similarity between the user's question and all questions in the JSON file\n",
    "similarities = []\n",
    "for item in data:\n",
    "    question_tokens = tokenizer.encode(item['question'], truncation=True, max_length=512, return_tensors='pt')\n",
    "    question_embedding = model(input_ids=question_tokens).last_hidden_state.mean(dim=1)\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    cosine_sim = torch.nn.functional.cosine_similarity(user_question_embedding, question_embedding)\n",
    "    similarities.append(cosine_sim.item())\n",
    "\n",
    "# Find the index of the question with the highest cosine similarity\n",
    "max_index = similarities.index(max(similarities))\n",
    "\n",
    "# Get the answer corresponding to the most similar question\n",
    "most_similar_answer = data[max_index]['answer']\n",
    "\n",
    "print(\"Most relevant answer:\", most_similar_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 36: When is a CDA needed?\n",
      "Cosine Similarity Score: 0.9119568467140198\n",
      "\n",
      "Question 50: Is a CDA needed for a facility visit?\n",
      "Cosine Similarity Score: 0.8341062664985657\n",
      "\n",
      "Question 78: What BI means in a CDA?\n",
      "Cosine Similarity Score: 0.8040212988853455\n",
      "\n",
      "Most relevant answer: A MANE Commercial Representative is appointed to assist for the promotion and sale of MANE's products (fragrances/ flavours/ ingredients), within a limited territory (country, region, city) for a specific market (fragrance/ flavour for the food/ cosmetic/ personal care/ home care, and less frequently, in fine fragrance, pharmaceutical, tobacco, pet food, and oral care industries), and grow MANE's direct sales accordingly. A MANE Distributor is appointed to resell 'as is' some of MANE's products (fragrances/ flavours/ ingredients), within a limited territory (country, region, city) for a specific market (fragrance/ flavour for the food/ cosmetic/ personal care/ home care, and less frequently, in fine fragrance, pharmaceutical, tobacco, pet food, and oral care industries) to its own customers.\n",
      "Cosine Similarity Score with most relevant question: 0.9119568467140198\n"
     ]
    }
   ],
   "source": [
    "\n",
    "user_question = input(\"Ask a question: \")\n",
    "threshold = 0.8\n",
    "similarities = []\n",
    "for i, item in enumerate(data):\n",
    "    question_tokens = tokenizer.encode(item['question'], truncation=True, max_length=512, return_tensors='pt')\n",
    "    question_embedding = model(input_ids=question_tokens).last_hidden_state.mean(dim=1)\n",
    "\n",
    "    cosine_sim = torch.nn.functional.cosine_similarity(user_question_embedding, question_embedding).item()\n",
    "\n",
    "    # Display only if similarity score is above the threshold\n",
    "    if cosine_sim > threshold:\n",
    "        print(f\"Question {i + 1}: {item['question']}\")\n",
    "        print(f\"Cosine Similarity Score: {cosine_sim}\")\n",
    "        print()\n",
    "\n",
    "        # Store the similarity score\n",
    "        similarities.append(cosine_sim)\n",
    "\n",
    "# Check if there are any similarities above the threshold\n",
    "if similarities:\n",
    "    # Sort the similarities in descending order\n",
    "    sorted_similarities = sorted(similarities, reverse=True)\n",
    "\n",
    "    # Find the index of the question with the highest cosine similarity\n",
    "    max_index = similarities.index(sorted_similarities[0])\n",
    "\n",
    "    # Get the answer corresponding to the most similar question\n",
    "    most_similar_answer = data[max_index]['answer']\n",
    "\n",
    "    print(\"Most relevant answer:\", most_similar_answer)\n",
    "    print(\"Cosine Similarity Score with most relevant question:\", sorted_similarities[0])\n",
    "\n",
    "    # Check the difference between the top two similarity scores\n",
    "    score_difference = sorted_similarities[0] - sorted_similarities[1]\n",
    "\n",
    "    # Set a threshold for prompting the user for more specificity\n",
    "    specificity_threshold = 0.05\n",
    "\n",
    "    if score_difference < specificity_threshold:\n",
    "        print(\"The similarity scores are very close. Please be more specific in your question.\")\n",
    "else:\n",
    "    print(\"No relevant questions found above the threshold.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Obtaining dependency information for spacy from https://files.pythonhosted.org/packages/90/f0/0133b684e18932c7bf4075d94819746cee2c0329f2569db526b0fa1df1df/spacy-3.7.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading spacy-3.7.2-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Obtaining dependency information for spacy-loggers<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/33/78/d1a1a026ef3af911159398c939b1509d5c36fe524c7b644f34a5146c4e16/spacy_loggers-1.0.5-py3-none-any.whl.metadata\n",
      "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Obtaining dependency information for murmurhash<1.1.0,>=0.28.0 from https://files.pythonhosted.org/packages/71/46/af01a20ec368bd9cb49a1d2df15e3eca113bbf6952cc1f2a47f1c6801a7f/murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Obtaining dependency information for cymem<2.1.0,>=2.0.2 from https://files.pythonhosted.org/packages/c1/c3/dd044e6f62a3d317c461f6f0c153c6573ed13025752d779e514000c15dd2/cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Obtaining dependency information for preshed<3.1.0,>=3.0.2 from https://files.pythonhosted.org/packages/e4/fc/78cdbdb79f5d6d45949e72c32445d6c060977ad50a1dcfc0392622165f7c/preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.3.0,>=8.1.8 (from spacy)\n",
      "  Obtaining dependency information for thinc<8.3.0,>=8.1.8 from https://files.pythonhosted.org/packages/dd/e9/c806bd2b281cc4cb5eea9375c3f45f6c4ff293877f469bb38d78a4f1cf96/thinc-8.2.1-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading thinc-8.2.1-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Obtaining dependency information for wasabi<1.2.0,>=0.9.1 from https://files.pythonhosted.org/packages/8f/69/26cbf0bad11703241cb84d5324d868097f7a8faf2f1888354dac8883f3fc/wasabi-1.1.2-py3-none-any.whl.metadata\n",
      "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Obtaining dependency information for srsly<3.0.0,>=2.4.3 from https://files.pythonhosted.org/packages/eb/f5/e3f29993f673d91623df6413ba64e815dd2676fd7932cbc5e7347402ddae/srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Obtaining dependency information for catalogue<2.1.0,>=2.0.6 from https://files.pythonhosted.org/packages/9e/96/d32b941a501ab566a16358d68b6eb4e4acc373fab3c3c4d7d9e649f7b4bb/catalogue-2.0.10-py3-none-any.whl.metadata\n",
      "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
      "  Obtaining dependency information for weasel<0.4.0,>=0.1.0 from https://files.pythonhosted.org/packages/d5/e5/b63b8e255d89ba4155972990d42523251d4d1368c4906c646597f63870e2/weasel-0.3.4-py3-none-any.whl.metadata\n",
      "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typer<0.10.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
      "     ---------------------------------------- 0.0/45.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 45.9/45.9 kB ? eta 0:00:00\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from spacy) (5.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from spacy) (4.65.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from spacy) (2.31.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from spacy) (1.10.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from spacy) (68.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from spacy) (23.1)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     ---------------------------------------- 0.0/181.6 kB ? eta -:--:--\n",
      "     -------------------------------------- 181.6/181.6 kB 5.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from spacy) (1.24.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.1.8->spacy)\n",
      "  Obtaining dependency information for blis<0.8.0,>=0.7.8 from https://files.pythonhosted.org/packages/2f/09/da0592c74560cc33396504698122f7a56747c82a5e072ca7d2c3397898e1/blis-0.7.11-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading blis-0.7.11-cp311-cp311-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.1.8->spacy)\n",
      "  Obtaining dependency information for confection<1.0.0,>=0.0.1 from https://files.pythonhosted.org/packages/39/78/f9d18da7b979a2e6007bfcea2f3c8cc02ed210538ae1ce7e69092aed7b18/confection-0.1.4-py3-none-any.whl.metadata\n",
      "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
      "  Obtaining dependency information for cloudpathlib<0.17.0,>=0.7.0 from https://files.pythonhosted.org/packages/0f/6e/45b57a7d4573d85d0b0a39d99673dc1f5eea9d92a1a4603b35e968fbf89a/cloudpathlib-0.16.0-py3-none-any.whl.metadata\n",
      "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n",
      "Downloading spacy-3.7.2-cp311-cp311-win_amd64.whl (12.1 MB)\n",
      "   ---------------------------------------- 0.0/12.1 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.2/12.1 MB 7.6 MB/s eta 0:00:02\n",
      "   -- ------------------------------------- 0.7/12.1 MB 8.8 MB/s eta 0:00:02\n",
      "   --- ------------------------------------ 1.2/12.1 MB 9.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.5/12.1 MB 8.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.0/12.1 MB 9.0 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 2.4/12.1 MB 9.0 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 2.8/12.1 MB 9.5 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 3.3/12.1 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.7/12.1 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 3.9/12.1 MB 8.9 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 4.4/12.1 MB 9.0 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 4.8/12.1 MB 9.0 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 5.3/12.1 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.8/12.1 MB 9.3 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.2/12.1 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 6.6/12.1 MB 9.2 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 7.1/12.1 MB 9.3 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.6/12.1 MB 9.3 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 8.2/12.1 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 8.7/12.1 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.1/12.1 MB 9.5 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.3/12.1 MB 9.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 10.0/12.1 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.5/12.1 MB 9.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 10.9/12.1 MB 9.8 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.5/12.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  11.9/12.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  12.1/12.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.1/12.1 MB 9.3 MB/s eta 0:00:00\n",
      "Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.8-cp311-cp311-win_amd64.whl (39 kB)\n",
      "Downloading murmurhash-1.0.10-cp311-cp311-win_amd64.whl (25 kB)\n",
      "Downloading preshed-3.0.9-cp311-cp311-win_amd64.whl (122 kB)\n",
      "   ---------------------------------------- 0.0/122.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 122.3/122.3 kB ? eta 0:00:00\n",
      "Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.4.8-cp311-cp311-win_amd64.whl (479 kB)\n",
      "   ---------------------------------------- 0.0/479.7 kB ? eta -:--:--\n",
      "   ------------------------------------- - 460.8/479.7 kB 14.5 MB/s eta 0:00:01\n",
      "   --------------------------------------- 479.7/479.7 kB 15.1 MB/s eta 0:00:00\n",
      "Downloading thinc-8.2.1-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 0.7/1.5 MB 10.6 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.2/1.5 MB 12.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 10.4 MB/s eta 0:00:00\n",
      "Downloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
      "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.1 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.1/50.1 kB ? eta 0:00:00\n",
      "Downloading blis-0.7.11-cp311-cp311-win_amd64.whl (6.6 MB)\n",
      "   ---------------------------------------- 0.0/6.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.4/6.6 MB 12.6 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 0.9/6.6 MB 11.6 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 1.4/6.6 MB 11.4 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 1.8/6.6 MB 10.5 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 2.4/6.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 2.8/6.6 MB 10.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 3.3/6.6 MB 11.1 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 3.8/6.6 MB 10.6 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 4.4/6.6 MB 10.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 4.8/6.6 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 5.5/6.6 MB 10.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.1/6.6 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  6.6/6.6 MB 11.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.6/6.6 MB 10.3 MB/s eta 0:00:00\n",
      "Downloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
      "   ---------------------------------------- 0.0/45.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 45.0/45.0 kB ? eta 0:00:00\n",
      "Downloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: cymem, wasabi, spacy-loggers, spacy-legacy, murmurhash, langcodes, cloudpathlib, catalogue, blis, typer, srsly, preshed, confection, weasel, thinc, spacy\n",
      "Successfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.1 typer-0.9.0 wasabi-1.1.2 weasel-0.3.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bert base model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 20: When should I involve the Legal & IP Department?\n",
      "Cosine Similarity Score: 0.8356700539588928\n",
      "Question 22: What is the role of the Legal & IP Department in the contract review process?\n",
      "Cosine Similarity Score: 0.8273530006408691\n",
      "Cosine Similarity Score with refined question: 0.8484472036361694\n",
      "Most relevant answer: The Legal & IP Department (the Legal Counsel previously involved in similar contracts with the same counterparty) must be copied on the correspondence regarding the contract review between all the involved departments, but the contract will only be submitted to the Legal & IP Department once all the required validations and comments are obtained.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "import spacy\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from difflib import SequenceMatcher\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "with open('modified_faq_data.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "user_question = input(\"Ask a question: \")\n",
    "\n",
    "user_question_tokens = tokenizer.encode(user_question, truncation=True, max_length=512, return_tensors='pt')\n",
    "user_question_embedding = model(input_ids=user_question_tokens).last_hidden_state.mean(dim=1)\n",
    "\n",
    "similarities = []\n",
    "for i, item in enumerate(data):\n",
    "    question_tokens = tokenizer.encode(item['question'], truncation=True, max_length=512, return_tensors='pt')\n",
    "    question_embedding = model(input_ids=question_tokens).last_hidden_state.mean(dim=1)\n",
    "\n",
    "    cosine_sim = torch.nn.functional.cosine_similarity(user_question_embedding, question_embedding).item()\n",
    "    similarities.append(cosine_sim)\n",
    "\n",
    "top_similar_indices = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)[:2]\n",
    "\n",
    "for idx in top_similar_indices:\n",
    "    print(f\"Question {idx + 1}: {data[idx]['question']}\")\n",
    "    print(f\"Cosine Similarity Score: {similarities[idx]}\")\n",
    "\n",
    "user_response = input(\"Do you want to clarify your question for better results? (yes/no): \")\n",
    "\n",
    "if user_response.lower() == 'yes':\n",
    "    prev_question = data[top_similar_indices[0]]['question']\n",
    "    refined_question = input(\"Please refine your question: \")\n",
    "\n",
    "    refined_tokens = nlp(refined_question)\n",
    "    refined_lemmas = \" \".join([token.lemma_ for token in refined_tokens])\n",
    "\n",
    "    prev_tokens = nlp(prev_question)\n",
    "    prev_lemmas = \" \".join([token.lemma_ for token in prev_tokens])\n",
    "\n",
    "    lemmatized_question = f\"{refined_lemmas} {prev_lemmas}\"\n",
    "    lemmatized_tokens = tokenizer.encode(lemmatized_question, truncation=True, max_length=512, return_tensors='pt')\n",
    "    lemmatized_embedding = model(input_ids=lemmatized_tokens).last_hidden_state.mean(dim=1)\n",
    "\n",
    "    prev_tokens = tokenizer.encode(prev_question, truncation=True, max_length=512, return_tensors='pt')\n",
    "    prev_embedding = model(input_ids=prev_tokens).last_hidden_state.mean(dim=1)\n",
    "    lemmatized_cosine_sim = torch.nn.functional.cosine_similarity(lemmatized_embedding, prev_embedding).item()\n",
    "\n",
    "    print(f\"Cosine Similarity Score with refined question: {lemmatized_cosine_sim}\")\n",
    "    if lemmatized_cosine_sim > 0.8:\n",
    "        print(\"Most relevant answer:\", data[top_similar_indices[0]]['answer'])\n",
    "    else:\n",
    "        print(\"No relevant answer found for the refined question.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.12.2\n",
      "  Downloading transformers-4.12.2-py3-none-any.whl (3.1 MB)\n",
      "     ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/3.1 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.0/3.1 MB 178.6 kB/s eta 0:00:17\n",
      "      --------------------------------------- 0.1/3.1 MB 252.2 kB/s eta 0:00:12\n",
      "     -- ------------------------------------- 0.2/3.1 MB 551.6 kB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 0.4/3.1 MB 1.1 MB/s eta 0:00:03\n",
      "     ------ --------------------------------- 0.5/3.1 MB 1.4 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 0.7/3.1 MB 1.7 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 0.9/3.1 MB 1.9 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 1.0/3.1 MB 2.0 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 1.2/3.1 MB 2.2 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 1.3/3.1 MB 2.2 MB/s eta 0:00:01\n",
      "     ------------------ --------------------- 1.5/3.1 MB 2.2 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 1.5/3.1 MB 2.2 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 1.5/3.1 MB 2.2 MB/s eta 0:00:01\n",
      "     -------------------- ------------------- 1.6/3.1 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 1.8/3.1 MB 2.1 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 1.9/3.1 MB 2.1 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 2.1/3.1 MB 2.3 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 2.3/3.1 MB 2.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 2.5/3.1 MB 2.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 2.7/3.1 MB 2.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 2.8/3.1 MB 2.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  3.0/3.1 MB 2.6 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 3.1/3.1 MB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: filelock in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from transformers==4.12.2) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.0.17 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from transformers==4.12.2) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from transformers==4.12.2) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from transformers==4.12.2) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from transformers==4.12.2) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from transformers==4.12.2) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from transformers==4.12.2) (2.31.0)\n",
      "Collecting sacremoses (from transformers==4.12.2)\n",
      "  Obtaining dependency information for sacremoses from https://files.pythonhosted.org/packages/0b/f0/89ee2bc9da434bd78464f288fdb346bc2932f2ee80a90b2a4bbbac262c74/sacremoses-0.1.1-py3-none-any.whl.metadata\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting tokenizers<0.11,>=0.10.1 (from transformers==4.12.2)\n",
      "  Downloading tokenizers-0.10.3.tar.gz (212 kB)\n",
      "     ---------------------------------------- 0.0/212.7 kB ? eta -:--:--\n",
      "     ------------------------- ------------ 143.4/212.7 kB 4.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 212.7/212.7 kB 3.3 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from transformers==4.12.2) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.0.17->transformers==4.12.2) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.0.17->transformers==4.12.2) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers==4.12.2) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from requests->transformers==4.12.2) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from requests->transformers==4.12.2) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from requests->transformers==4.12.2) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from requests->transformers==4.12.2) (2023.7.22)\n",
      "Requirement already satisfied: click in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from sacremoses->transformers==4.12.2) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\wissa\\anaconda3\\lib\\site-packages (from sacremoses->transformers==4.12.2) (1.2.0)\n",
      "Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "   ---------------------------------------- 0.0/897.5 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 204.8/897.5 kB 6.3 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 337.9/897.5 kB 4.2 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 491.5/897.5 kB 4.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 634.9/897.5 kB 4.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 819.2/897.5 kB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  890.9/897.5 kB 3.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 897.5/897.5 kB 3.5 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: tokenizers\n",
      "  Building wheel for tokenizers (pyproject.toml): started\n",
      "  Building wheel for tokenizers (pyproject.toml): finished with status 'error'\n",
      "Failed to build tokenizers\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Building wheel for tokenizers (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [51 lines of output]\n",
      "      running bdist_wheel\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib.win-amd64-cpython-311\n",
      "      creating build\\lib.win-amd64-cpython-311\\tokenizers\n",
      "      copying py_src\\tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\n",
      "      creating build\\lib.win-amd64-cpython-311\\tokenizers\\models\n",
      "      copying py_src\\tokenizers\\models\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\models\n",
      "      creating build\\lib.win-amd64-cpython-311\\tokenizers\\decoders\n",
      "      copying py_src\\tokenizers\\decoders\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\decoders\n",
      "      creating build\\lib.win-amd64-cpython-311\\tokenizers\\normalizers\n",
      "      copying py_src\\tokenizers\\normalizers\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\normalizers\n",
      "      creating build\\lib.win-amd64-cpython-311\\tokenizers\\pre_tokenizers\n",
      "      copying py_src\\tokenizers\\pre_tokenizers\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\pre_tokenizers\n",
      "      creating build\\lib.win-amd64-cpython-311\\tokenizers\\processors\n",
      "      copying py_src\\tokenizers\\processors\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\processors\n",
      "      creating build\\lib.win-amd64-cpython-311\\tokenizers\\trainers\n",
      "      copying py_src\\tokenizers\\trainers\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\trainers\n",
      "      creating build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
      "      copying py_src\\tokenizers\\implementations\\base_tokenizer.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
      "      copying py_src\\tokenizers\\implementations\\bert_wordpiece.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
      "      copying py_src\\tokenizers\\implementations\\byte_level_bpe.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
      "      copying py_src\\tokenizers\\implementations\\char_level_bpe.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
      "      copying py_src\\tokenizers\\implementations\\sentencepiece_bpe.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
      "      copying py_src\\tokenizers\\implementations\\sentencepiece_unigram.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
      "      copying py_src\\tokenizers\\implementations\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\implementations\n",
      "      creating build\\lib.win-amd64-cpython-311\\tokenizers\\tools\n",
      "      copying py_src\\tokenizers\\tools\\visualizer.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\tools\n",
      "      copying py_src\\tokenizers\\tools\\__init__.py -> build\\lib.win-amd64-cpython-311\\tokenizers\\tools\n",
      "      copying py_src\\tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\n",
      "      copying py_src\\tokenizers\\models\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\\models\n",
      "      copying py_src\\tokenizers\\decoders\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\\decoders\n",
      "      copying py_src\\tokenizers\\normalizers\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\\normalizers\n",
      "      copying py_src\\tokenizers\\pre_tokenizers\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\\pre_tokenizers\n",
      "      copying py_src\\tokenizers\\processors\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\\processors\n",
      "      copying py_src\\tokenizers\\trainers\\__init__.pyi -> build\\lib.win-amd64-cpython-311\\tokenizers\\trainers\n",
      "      copying py_src\\tokenizers\\tools\\visualizer-styles.css -> build\\lib.win-amd64-cpython-311\\tokenizers\\tools\n",
      "      running build_ext\n",
      "      running build_rust\n",
      "      error: can't find Rust compiler\n",
      "      \n",
      "      If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "      \n",
      "      To update pip, run:\n",
      "      \n",
      "          pip install --upgrade pip\n",
      "      \n",
      "      and then retry package installation.\n",
      "      \n",
      "      If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tokenizers\n",
      "ERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\n"
     ]
    }
   ],
   "source": [
    "pip install transformers==4.12.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bert large model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10287bd2da91490ba0050212782994c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wissa\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\wissa\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b48402f26d4a9b8e535093f36191ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d1f196255e54f299d5be84d56d25b05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2080b91a53c4e8881a29e71da2b083a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "479c0c1ae8f54e1ca99b6de02bec62f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 2: What is the difference between a Commercial Representative and an Agent?\n",
      "Cosine Similarity Score: 0.9401176571846008\n",
      "Question 1: What is the difference between a Commercial Representative and a Distributor?\n",
      "Cosine Similarity Score: 0.9188472628593445\n",
      "Cosine Similarity Score with refined question: 0.9340527653694153\n",
      "Most relevant answer: An Agent is entitled to negotiate selling prices on behalf of the company it represents, while a Commercial Representative is not. MANE does not appoint Agents, only Commercial Representatives.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model = BertModel.from_pretrained('bert-large-uncased')\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "with open('modified_faq_data.json', 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "user_question = input(\"Ask a question: \")\n",
    "\n",
    "user_question_tokens = tokenizer.encode(user_question, truncation=True, max_length=512, return_tensors='pt')\n",
    "user_question_embedding = model(input_ids=user_question_tokens).last_hidden_state.mean(dim=1)\n",
    "\n",
    "similarities = []\n",
    "for i, item in enumerate(data):\n",
    "    question_tokens = tokenizer.encode(item['question'], truncation=True, max_length=512, return_tensors='pt')\n",
    "    question_embedding = model(input_ids=question_tokens).last_hidden_state.mean(dim=1)\n",
    "    cosine_sim = torch.nn.functional.cosine_similarity(user_question_embedding, question_embedding, dim=1).item()\n",
    "    similarities.append(cosine_sim)\n",
    "top_similar_indices = sorted(range(len(similarities)), key=lambda i: similarities[i], reverse=True)[:2]\n",
    "for idx in top_similar_indices:\n",
    "    print(f\"Question {idx + 1}: {data[idx]['question']}\")\n",
    "    print(f\"Cosine Similarity Score: {similarities[idx]}\")\n",
    "\n",
    "user_response = input(\"Do you want to clarify your question for better results? (yes/no): \")\n",
    "\n",
    "if user_response.lower() == 'yes':\n",
    "    prev_question = data[top_similar_indices[0]]['question']\n",
    "    refined_question = input(\"Please refine your question: \")\n",
    "    refined_tokens = nlp(refined_question)\n",
    "    refined_lemmas = \" \".join([token.lemma_ for token in refined_tokens])\n",
    "\n",
    "    prev_tokens = nlp(prev_question)\n",
    "    prev_lemmas = \" \".join([token.lemma_ for token in prev_tokens])\n",
    "\n",
    "    lemmatized_question = f\"{refined_lemmas} {prev_lemmas}\"\n",
    "    lemmatized_tokens = tokenizer.encode(lemmatized_question, truncation=True, max_length=512, return_tensors='pt')\n",
    "    lemmatized_embedding = model(input_ids=lemmatized_tokens).last_hidden_state.mean(dim=1)\n",
    "\n",
    "    prev_tokens = tokenizer.encode(prev_question, truncation=True, max_length=512, return_tensors='pt')\n",
    "    prev_embedding = model(input_ids=prev_tokens).last_hidden_state.mean(dim=1)\n",
    "    lemmatized_cosine_sim = torch.nn.functional.cosine_similarity(lemmatized_embedding, prev_embedding, dim=1).item()\n",
    "\n",
    "    print(f\"Cosine Similarity Score with refined question: {lemmatized_cosine_sim}\")\n",
    "    if lemmatized_cosine_sim > 0.8:\n",
    "        print(\"Most relevant answer:\", data[top_similar_indices[0]]['answer'])\n",
    "    else:\n",
    "        print(\"No relevant answer found for the refined question.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
